{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GraphEnricher (Read-Only / Dry Run)\n",
    "\n",
    "This notebook constructs an enriched AOP graph **in memory only** and exports it as JSON/CSV.\n",
    "\n",
    "- No connections to Neo4j\n",
    "- No CREATE/MERGE/DELETE queries\n",
    "- Safe to run repeatedly\n",
    "- Designed for downstream ingestion or visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Guarantees\n",
    "- The workflow is strictly read-only against your data sources.\n",
    "- All outputs are written to the `data/exports/` directory as:\n",
    "  - `graph_readonly.json` (nodes + relationships)\n",
    "  - `nodes.csv`\n",
    "  - `relationships.csv`\n",
    "- Optional: a Cypher preview file with MERGE statements can be generated for out-of-band loading (kept off by default).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports & configuration\n",
    "from datetime import datetime\n",
    "import os, json, csv, re\n",
    "import xmltodict\n",
    "\n",
    "DRY_RUN = True  # Always True: no DB writes\n",
    "GENERATE_CYPHER_PREVIEW = False  # Optional, off by default\n",
    "\n",
    "# Paths (adjust if needed)\n",
    "PROJECT_ROOT = r'e:/aop-network-visualizer/aop-visualizer-clean'\n",
    "DATA_DIR = os.path.join(PROJECT_ROOT, 'data')\n",
    "INPUT_XML_PATH = os.path.join(DATA_DIR, 'aop-wiki-xml-2025-07-01', 'aop-wiki-xml-2025-07-01')\n",
    "EXPORT_DIR = os.path.join(DATA_DIR, 'exports')\n",
    "os.makedirs(EXPORT_DIR, exist_ok=True)\n",
    "\n",
    "NB_STARTED_AT = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "print('Notebook started at:', NB_STARTED_AT)\n",
    "print('XML input:', INPUT_XML_PATH)\n",
    "print('Export dir:', EXPORT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utilities\n",
    "CLEANR = re.compile(r'<.*?>|&([a-z0-9]+|#[0-9]{1,6}|#x[0-9a-f]{1,6});', re.IGNORECASE)\n",
    "\n",
    "def cleanhtml(raw_html):\n",
    "    if not raw_html:\n",
    "        return raw_html\n",
    "    text = re.sub(CLEANR, '', raw_html)\n",
    "    return text.replace('\\n', ' ').strip()\n",
    "\n",
    "def normalize_list(x):\n",
    "    if x is None:\n",
    "        return []\n",
    "    return x if isinstance(x, list) else [x]\n",
    "\n",
    "def safe_get(d, keys, default=None):\n",
    "    # Get first present key among keys (no deep traversal)\n",
    "    for k in keys:\n",
    "        if k in d:\n",
    "            return d[k]\n",
    "    return default\n",
    "\n",
    "def write_json(path, data):\n",
    "    with open(path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, ensure_ascii=False)\n",
    "    print('Wrote JSON:', path)\n",
    "\n",
    "def write_csv(path, rows, headers):\n",
    "    with open(path, 'w', encoding='utf-8', newline='') as f:\n",
    "        writer = csv.DictWriter(f, fieldnames=headers)\n",
    "        writer.writeheader()\n",
    "        for r in rows:\n",
    "            writer.writerow(r)\n",
    "    print('Wrote CSV:', path)\n",
    "\n",
    "def to_json_str(obj):\n",
    "    try:\n",
    "        return json.dumps(obj, ensure_ascii=False)\n",
    "    except Exception:\n",
    "        return ''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load AOP-Wiki XML\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(INPUT_XML_PATH, encoding='utf-8') as xml_file:\n",
    "    data_dict = xmltodict.parse(xml_file.read())\n",
    "\n",
    "data = data_dict.get('data') or {}\n",
    "print('Top-level keys:', list(data.keys())[:10])\n",
    "\n",
    "# Vendor references (maps internal ids -> public ids)\n",
    "vendor = data.get('vendor-specific') or {}\n",
    "aop_refs = normalize_list(vendor.get('aop-reference'))\n",
    "ke_refs = normalize_list(vendor.get('key-event-reference'))\n",
    "stressor_refs = normalize_list(vendor.get('stressor-reference'))\n",
    "ker_refs = normalize_list(vendor.get('key-event-relationship-reference'))\n",
    "\n",
    "aop_id_to_wiki = {}  # internal '@id' -> '@aop-wiki-id'\n",
    "for it in aop_refs:\n",
    "    iid = it.get('@id')\n",
    "    wid = it.get('@aop-wiki-id')\n",
    "    if iid and wid:\n",
    "        aop_id_to_wiki[iid] = wid\n",
    "\n",
    "ke_id_to_wiki = {}   # internal '@id' -> '@aop-wiki-id' (event id)\n",
    "for it in ke_refs:\n",
    "    iid = it.get('@id')\n",
    "    wid = it.get('@aop-wiki-id')\n",
    "    if iid and wid:\n",
    "        ke_id_to_wiki[iid] = wid\n",
    "\n",
    "print('AOP refs:', len(aop_id_to_wiki), ' KE refs:', len(ke_id_to_wiki))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Nodes (AOP, KeyEvent/MIE/AO)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = []\n",
    "nodes_by_id = {}\n",
    "relationships = []\n",
    "\n",
    "def add_node(node):\n",
    "    nid = node['id']\n",
    "    if nid not in nodes_by_id:\n",
    "        nodes_by_id[nid] = node\n",
    "        nodes.append(node)\n",
    "\n",
    "# AOP nodes\n",
    "for aop in normalize_list(data.get('aop')):\n",
    "    internal_id = aop.get('@id')\n",
    "    wiki_id = aop_id_to_wiki.get(internal_id) or internal_id\n",
    "    node_id = f'Aop:{wiki_id}'\n",
    "    title = aop.get('title') or aop.get('short-name') or f'AOP {wiki_id}'\n",
    "    props = {\n",
    "        'short_name': aop.get('short-name'),\n",
    "        'authors': cleanhtml(aop.get('authors')),\n",
    "        'oecd_project': aop.get('oecd-project'),\n",
    "        'abstract': cleanhtml(aop.get('abstract')),\n",
    "        'potential_applications': cleanhtml(aop.get('potential-applications')),\n",
    "        'references': cleanhtml(aop.get('references')),\n",
    "        'essentiality_support': cleanhtml(aop.get('essentiality-support')),\n",
    "        'source': aop.get('source'),\n",
    "        'background': cleanhtml(aop.get('background')),\n",
    "        'creation_timestamp': aop.get('creation-timestamp'),\n",
    "        'last_modification_timestamp': aop.get('last-modification-timestamp'),\n",
    "    }\n",
    "    add_node({\n",
    "        'id': node_id,\n",
    "        'label': title,\n",
    "        'type': 'AOP',\n",
    "        'url': f'https://aopwiki.org/aops/{wiki_id}' if wiki_id else None,\n",
    "        'props': props\n",
    "    })\n",
    "\n",
    "# KE/MIE/AO nodes\n",
    "for ke in normalize_list(data.get('key-event')):\n",
    "    internal_id = ke.get('@id')\n",
    "    wiki_id = ke_id_to_wiki.get(internal_id) or internal_id\n",
    "    ke_type_raw = (ke.get('key-event-type') or ke.get('event-type') or ke.get('type') or '').strip()\n",
    "    node_type = 'KeyEvent'\n",
    "    if ke_type_raw.lower() == 'molecularinitiatingevent':\n",
    "        node_type = 'MolecularInitiatingEvent'\n",
    "    elif ke_type_raw.lower() == 'adverseoutcome':\n",
    "        node_type = 'AdverseOutcome'\n",
    "\n",
    "    name = ke.get('name') or ke.get('short-name') or f'KE {wiki_id}'\n",
    "\n",
    "    # Organ/cell terms often nested dicts\n",
    "    organ_term = ke.get('organ-term') or {}\n",
    "    cell_term = ke.get('cell-term') or {}\n",
    "\n",
    "    applicability = ke.get('applicability') or {}\n",
    "    # Normalize applicability into simple lists\n",
    "    def norm_tax(v):\n",
    "        out = []\n",
    "        for it in normalize_list(v):\n",
    "            if isinstance(it, dict):\n",
    "                tid = it.get('@taxonomy-id') or it.get('taxonomy') or it.get('id')\n",
    "                if tid:\n",
    "                    out.append(str(tid))\n",
    "        return sorted(set(out))\n",
    "\n",
    "    def norm_simple(v, key):\n",
    "        out = []\n",
    "        for it in normalize_list(v):\n",
    "            if isinstance(it, dict):\n",
    "                val = it.get(key)\n",
    "                if val:\n",
    "                    out.append(str(val))\n",
    "            else:\n",
    "                out.append(str(it))\n",
    "        return sorted(set(out))\n",
    "\n",
    "    applicability_out = {\n",
    "        'taxonomy': norm_tax(applicability.get('taxonomy')),\n",
    "        'sex': norm_simple(applicability.get('sex'), 'sex'),\n",
    "        'life_stage': norm_simple(applicability.get('life-stage'), 'life-stage'),\n",
    "    }\n",
    "\n",
    "    props = {\n",
    "        'short_name': ke.get('short-name'),\n",
    "        'biological_organization_level': ke.get('biological-organization-level'),\n",
    "        'organ_term': organ_term.get('term') or organ_term.get('label'),\n",
    "        'organ_source_id': organ_term.get('source-id'),\n",
    "        'cell_term': cell_term.get('term') or cell_term.get('label'),\n",
    "        'cell_source_id': cell_term.get('source-id'),\n",
    "        'applicability': applicability_out,\n",
    "        'ke_type': ke_type_raw or node_type,\n",
    "    }\n",
    "\n",
    "    add_node({\n",
    "        'id': f'KE:{wiki_id}',\n",
    "        'label': name,\n",
    "        'type': node_type,\n",
    "        'url': f'https://aopwiki.org/events/{wiki_id}' if wiki_id else None,\n",
    "        'props': props\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Relationships (KER + AOP membership via KER)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to add rels without duplication\n",
    "rels_set = set()  # (source, type, target, aop_opt)\n",
    "\n",
    "def add_rel(source, rtype, target, props=None, aop=None, rid=None):\n",
    "    key = (source, rtype, target, aop)\n",
    "    if key in rels_set:\n",
    "        return\n",
    "    rels_set.add(key)\n",
    "    relationships.append({\n",
    "        'id': rid or f'{rtype}:{len(relationships)+1}',\n",
    "        'type': rtype,\n",
    "        'source': source,\n",
    "        'target': target,\n",
    "        'aop': aop,\n",
    "        'props': props or {}\n",
    "    })\n",
    "\n",
    "# Build KER (Key Event Relationship) edges\n",
    "ker_items = normalize_list(data.get('key-event-relationship'))\n",
    "for ker in ker_items:\n",
    "    # Extract upstream/downstream internal ids\n",
    "    up_internal = (ker.get('upstream-id') or\n",
    "                   (ker.get('upstream-key-event') or {}).get('@id') or\n",
    "                   ker.get('@upstream-id'))\n",
    "    down_internal = (ker.get('downstream-id') or\n",
    "                     (ker.get('downstream-key-event') or {}).get('@id') or\n",
    "                     ker.get('@downstream-id'))\n",
    "    aop_internal = ker.get('@aop-id') or ker.get('aop-id')\n",
    "    ker_internal_id = ker.get('@id')\n",
    "\n",
    "    if not up_internal or not down_internal:\n",
    "        continue\n",
    "\n",
    "    up_wiki = ke_id_to_wiki.get(up_internal) or up_internal\n",
    "    down_wiki = ke_id_to_wiki.get(down_internal) or down_internal\n",
    "    aop_wiki = aop_id_to_wiki.get(aop_internal) or aop_internal if aop_internal else None\n",
    "\n",
    "    up_node = f'KE:{up_wiki}'\n",
    "    down_node = f'KE:{down_wiki}'\n",
    "    aop_node = f'Aop:{aop_wiki}' if aop_wiki else None\n",
    "\n",
    "    # Relationship properties (safely collect a few known fields if present)\n",
    "    rprops = {}\n",
    "    for k in ['weight-of-evidence', 'quantitative-understanding', 'biological-plausibility', 'evidence-support']:\n",
    "        if k in ker:\n",
    "            rprops[k] = ker.get(k)\n",
    "\n",
    "    add_rel(up_node, 'KEY_EVENT_RELATIONSHIP', down_node, props=rprops, aop=aop_node, rid=f'KER:{ker_internal_id}' if ker_internal_id else None)\n",
    "\n",
    "    # Also attach AOP membership via KER endpoints\n",
    "    if aop_node:\n",
    "        add_rel(aop_node, 'HAS_EVENT', up_node)\n",
    "        add_rel(aop_node, 'HAS_EVENT', down_node)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "node_types = Counter(n['type'] for n in nodes)\n",
    "rel_types = Counter(r['type'] for r in relationships)\n",
    "print('Nodes:', len(nodes), node_types)\n",
    "print('Rels :', len(relationships), rel_types)\n",
    "\n",
    "# Quick sanity: ensure no Neo4j operations present\n",
    "assert DRY_RUN is True\n",
    "print('Read-only guard active: No DB writes were performed.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export (JSON/CSV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JSON export\n",
    "json_path = os.path.join(EXPORT_DIR, 'graph_readonly.json')\n",
    "write_json(json_path, {'nodes': nodes, 'relationships': relationships})\n",
    "\n",
    "# CSV export\n",
    "nodes_csv = os.path.join(EXPORT_DIR, 'nodes.csv')\n",
    "rels_csv = os.path.join(EXPORT_DIR, 'relationships.csv')\n",
    "\n",
    "node_rows = [{\n",
    "    'id': n['id'],\n",
    "    'label': n.get('label'),\n",
    "    'type': n.get('type'),\n",
    "    'url': n.get('url') or '',\n",
    "    'props': to_json_str(n.get('props') or {})\n",
    "} for n in nodes]\n",
    "\n",
    "rel_rows = [{\n",
    "    'id': r.get('id'),\n",
    "    'type': r.get('type'),\n",
    "    'source': r.get('source'),\n",
    "    'target': r.get('target'),\n",
    "    'aop': r.get('aop') or '',\n",
    "    'props': to_json_str(r.get('props') or {})\n",
    "} for r in relationships]\n",
    "\n",
    "write_csv(nodes_csv, node_rows, headers=['id','label','type','url','props'])\n",
    "write_csv(rels_csv, rel_rows, headers=['id','type','source','target','aop','props'])\n",
    "\n",
    "print('Done.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Cypher MERGE preview (no execution)\n",
    "Toggle `GENERATE_CYPHER_PREVIEW` above to True if you want to generate a `.cypher` file with MERGE statements for out-of-band loading.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if GENERATE_CYPHER_PREVIEW:\n",
    "    cypher_path = os.path.join(EXPORT_DIR, 'preview_merge.cypher')\n",
    "    with open(cypher_path, 'w', encoding='utf-8') as f:\n",
    "        # Nodes\n",
    "        for n in nodes:\n",
    "            label = n['type']\n",
    "            nid = json.dumps(n['id'])\n",
    "            nprops = json.dumps(n.get('props') or {}, ensure_ascii=False)\n",
    "            url = json.dumps(n.get('url'))\n",
    "            text = f"MERGE (n:{label} { { 'id': {nid} } }) SET n += {nprops}, n.label={json.dumps(n.get('label'))}, n.url={url};\\n"\n",
    "            f.write(text)\n",
    "        f.write('\n')\n",
    "        # Relationships\n",
    "        for r in relationships:\n",
    "            st = json.dumps(r['source'])\n",
    "            tt = json.dumps(r['target'])\n",
    "            rtype = r['type']\n",
    "            rprops = json.dumps(r.get('props') or {}, ensure_ascii=False)\n",
    "            text = (\n",
    "                f"MATCH (s {{id: {st}}}), (t {{id: {tt}}}) MERGE (s)-[rel:{rtype}]->(t) SET rel += {rprops};\\n"\n",
    "            )\n",
    "            f.write(text)\n",
    "    print('Wrote Cypher preview:', cypher_path)\n",
    "else:\n",
    "    print('Cypher preview generation is OFF (set GENERATE_CYPHER_PREVIEW=True to enable).')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
